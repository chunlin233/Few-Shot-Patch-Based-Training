{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598421072113",
   "display_name": "Python 3.8.2 64-bit ('pytorch_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 32, 32])\n49\ntorch.Size([1, 1, 32, 32])\n"
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "\n",
    "t.manual_seed(1000)\n",
    "m = t.randn([1,32,32])*2 + 2.\n",
    "print(m.shape)\n",
    "m[m < 0.4] = 0\n",
    "device = 'cpu'\n",
    "erosion_weights = t.ones((1, 1, 7, 7)).to(device)\n",
    "m = F.conv2d(m.unsqueeze(0), erosion_weights, stride=1, padding=3)\n",
    "print(erosion_weights.numel())\n",
    "m[m < erosion_weights.numel()] = 0\n",
    "m /= erosion_weights.numel()\n",
    "print(m.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([995, 2])\n995\n995\n"
    }
   ],
   "source": [
    "valid_indices = []\n",
    "valid_indices_left = []\n",
    "# print(x.nonzero())\n",
    "for i in range(2):\n",
    "    valid_indices.append(m.squeeze().nonzero(as_tuple=False))\n",
    "    valid_indices_left.append(list(range(0, len(valid_indices[i]))))\n",
    "\n",
    "print(valid_indices[0].shape)\n",
    "print(valid_indices[0].numel() // 2)\n",
    "print(len(valid_indices_left[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\n175 328\ntensor([ 5, 26])\ntensor([10, 19])\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "item = 0\n",
    "im_index = item % 2\n",
    "midpoint_id = np.random.randint(0, len(valid_indices_left[im_index]))\n",
    "midpoint_r_id = np.random.randint(0, len(valid_indices[im_index]))\n",
    "midpoint = valid_indices[im_index][valid_indices_left[im_index][midpoint_id], :].squeeze()\n",
    "midpoint_r = valid_indices[im_index][midpoint_r_id, :].squeeze()\n",
    "\n",
    "print(len(valid_indices[im_index]) == len(valid_indices_left[im_index]))\n",
    "print(midpoint_id, midpoint_r_id)\n",
    "print(midpoint)\n",
    "print(midpoint_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_patches(im_index, midpoint, midpoint_r, size):\n",
    "    patch_pre = cut_patch(images_pre[im_index], midpoint, size)\n",
    "    if geom_blur_coeff != 0.0:\n",
    "        geom_blur_patch = get_geometric_blur_patch(images_pre_geom[im_index], midpoint, size, \\\n",
    "        geom_blur_coeff)\n",
    "        patch_pre = torch.cat((patch_pre, geom_blur_patch), dim=0)\n",
    "\n",
    "    if len(images_x1) > 0:\n",
    "        patch_x1 = cut_patch(images_x1[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x1), dim=0)\n",
    "    if len(images_x2) > 0:\n",
    "        patch_x2 = cut_patch(images_x2[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x2), dim=0)\n",
    "    if len(images_x3) > 0:\n",
    "        patch_x3 = cut_patch(images_x3[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x3), dim=0)\n",
    "    if len(images_x4) > 0:\n",
    "        patch_x4 = cut_patch(images_x4[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x4), dim=0)\n",
    "    if len(images_x5) > 0:\n",
    "        patch_x5 = cut_patch(images_x5[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x5), dim=0)\n",
    "    if len(images_x6) > 0:\n",
    "        patch_x6 = cut_patch(images_x6[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x6), dim=0)\n",
    "    if len(images_x7) > 0:\n",
    "        patch_x7 = cut_patch(images_x7[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x7), dim=0)\n",
    "    if len(images_x8) > 0:\n",
    "        patch_x8 = cut_patch(images_x8[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x8), dim=0)\n",
    "    if len(images_x9) > 0:\n",
    "        patch_x9 = cut_patch(images_x9[im_index], midpoint, size)\n",
    "        patch_pre = torch.cat((patch_pre, patch_x9), dim=0)\n",
    "\n",
    "    patch_post = cut_patch(images_post[im_index], midpoint, size)\n",
    "    patch_random = cut_patch(images_post[im_index], midpoint_r, size)\n",
    "\n",
    "    return patch_pre, patch_post, patch_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 32\n",
    "patch_pre, patch_post, patch_random = cut_patches(im_index, midpoint, midpoint_r, patch_size)"
   ]
  }
 ]
}